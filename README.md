# DataBase Creation

Дипломна робота складається з двох програмних модулів:
- Модуль наповнення бази даних (цей репозиторій)
- [Веб-додаток](https://github.com/PiatachenkoMila/dictionary-web-application)
## Технічне забезпечення
Програмна частина дипломної роботи виконувалась мовою програмування Python;
версія інтерпретатора: 3.7.2

Мінімальне технічне забезпечення:
- Python>=3.6.0<3.9.0
- DbBrowserForSqlite
- Текстовий редактор

## Встановлення
Перед початком роботи потрібно створити віртуальне середовище розроблення.

Відкрийте командний рядок та введіть команду:

```
python -m venv project_dictionary_venv
```
Активуйте віртуальне середовище за допомогою команди:
```
project_dictionary_venv\Scripts\activate
```

Встановіть необхідні python-бібліотеки за допомогою команди:
```
pip install -r requirements.txt
```

## База даних
Файл бази даних можна завантажити [за покликанням](https://drive.google.com/drive/folders/1LbtnmXV0c-Veh1Sn8KZWRokF-EaI-WZd).
Файл бази даних потрібно помістити до кореневої теки цього проекту.
## Порядок наповнення бази даних
Наповнення бази даних складається з таких етапів:

0. Імпорт словоформ з текстових файлів
1. Завантаження текстів кінотематики з Інтернету
2. Розпізнавання іменованих сутностей в завантажених текстах
3. Оновлення частотного словника
4. Оновлення конкордансу

Крок (0.) виконується лише один раз після фіналізації переліку термінів та 
укладання списку словоформ.

Кроки (1. - 4. ) можуть виконуватись багаторазово, але в строгій послідовності.

### Імпорт словоформ
Словоформи термінів містяться у файлі WORDFORMS.txt

Словоформи відібраних 50 іменованих сутностей містяться у файлі WORDFORMS_ner.txt

Кожен рядок текстового файлу містить список словоформ певної лексеми у такому форматі:
```
лексема:словоформа1;словоформа2;словоформаN;
```
Де "лексема" - це значення поля term певного рядка таблиці terms

Усі слова у файлі мають бути написати у нижньому регістрі.

Приклад рядка словоформ:
```
жанр:жанру;жанрові;жанром;жанрі;жанре;жанри;жанрів;жанрам;жанрами;жанрах;
```

Для імпорту словоформ з файлів WORDFORMS.txt та WORDFORMS_ner.txt потрібно виконати команду:
```
python import_wordforms_main.py
```
Для запуску імпорту словоформ з txt-файлів, розташованих в інших теках, потрібно запустити таку команду:
```
python import_wordforms_main.py --wordforms-file ім'я_файлу_зі_словоформами_термінів --wordforms-file-ner ім'я_файлу_зі_словоформами_ім_сутностей
```
Дані у текстових файлах WORDFORMS.txt та WORDFORMS_ner.txt збережені у кодуванні
<b>windows-1251</b>. У разі виникнення проблем з прочитанням даних файлів, потрібно змінити назву кодування у файлі <b>wordforms_freq_dict.py</b> (рядок 16).
```
        with open(filename, 'r', encoding='windows-1251') as f_in:
```

### Завантаження текстів
Для запуску скрипта завантаження текстів з Інтернету потрібно виконати команду:
```
python update_corpus_main.py
```
Після запуску даного скрипта буде запропоновано вибрати корпус для оновлення:
```
Corpora update program
(Type 0 to exit)
Select corpus to update
1: CinemaBlend https://www.cinemablend.com/news
2: MovieStape http://moviestape.net/novyny_kino/
3: Other texts (English)
4: Other texts (Ukrainian)
5: KinoFilmsUa https://www.kinofilms.ua/ukr/news/
6: KinoTeatrUa https://kino-teatr.ua/uk/main/news
```
4 із 6 корпусів тестів у базі даних підтримують оновлення (скачування нових текстів з Інтернету):
- [CinemaBlend](https://www.cinemablend.com/news)
- [MoviesTape](http://moviestape.net/novyny_kino/)
- [KinoFilmsUA](https://www.kinofilms.ua/ukr/news/)
- [KinoTeatrUa](https://kino-teatr.ua/uk/main/news)

+ Обравши корпус 2, або 5, або 6, потрібно вказати першу та останню сторінку з текстами новин
+ Обравши корпус 1 (CinemaBlend), потрібно вказати номери веб-сторінок 
з найновішим та найстарішим текстом, який Ви бажаєте завантажити.
### Розпізнавання іменованих сутностей
Розпізнавання іменованих сутностей в текстах, збережених до бази даних, рекомендується здійснювати з використанням графічного процесора.

Запуск даного процесу без підтримки графічного процесора (на центральному процесорі) займе набагато більше часу.
Файл моделі для розпізнавання іменованих сутностей українською мовою можна завантажити за [цим покликанням](https://github.com/gawy/stanza-lang-uk/releases/tag/v0.9)
Потрібно завантажити файл uk_languk_nertagger.pt
#### Запуск з використанням графічного процесора
Цю частину виконано у хмарному середовищі Google Colaboratory у власному Google-аккаунті.
Авторизувавшись у своєму Google-аккаунті, перейдіть за покликанням:
https://colab.research.google.com/notebooks/intro.ipynb

Потрібно вибрати Файл -> Новий записник / файл -> Новый блокнот / File -> New Notebook
Після цього у вашому Google Drive буде створено теку Colab Notebooks.
До цієї теки потрібно помістити такі файли:
+ dictionary.db
+ database_functions.py
+ extract_ner.py
+ uk_languk_nertagger.pt
+ Файл MyNotebook.ipynb, розміщений в теці [Colab даного репозиторію](Colab).

У теці Colab Notebooks відкрийте файл MyNotebook.ipynb (Open with -> Google Colaboratory)

Виберіть "Середовище виконання" -> "Змінити тип середовища виконання", вибрати GPU

Після цього виберіть "Середовище виконання" -> "Виконати всі"

#### Запуск з використанням центрального процесора
Всередині віртуального середовища виконайте команду:
```
pip install stanza==1.1.1
```

Запуск процесу розпізнавання за допомогою команди:
```
python extract_ner.py
```

### Укладання частотного словника
Запуск процесу оновлення частотного словника за допомогою команди:
```
python update_frequencies_main.py
```

### Укладання конкорданса
Запуск процесу оновлення конкорданса за допомогою команди:
```
python update_concordance_main.py
```
